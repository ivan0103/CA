{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T14:06:41.076219Z",
     "start_time": "2025-04-03T14:06:38.967270Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install transformers torch accelerate torchvision",
   "id": "1c9b9b0579b000a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (4.50.3)\r\n",
      "Requirement already satisfied: torch in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (2.6.0)\r\n",
      "Requirement already satisfied: optimum-quanto in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (0.2.7)\r\n",
      "Requirement already satisfied: accelerate in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (1.6.0)\r\n",
      "Requirement already satisfied: torchvision in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (0.17.2)\r\n",
      "Requirement already satisfied: filelock in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (3.17.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (0.30.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch) (3.1.5)\r\n",
      "Requirement already satisfied: fsspec in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: ninja in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from optimum-quanto) (1.11.1.4)\r\n",
      "Requirement already satisfied: psutil in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from accelerate) (6.1.1)\r\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting torchvision\r\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/29/88/00c69db213ee2443ada8886ec60789b227e06bb869d85ee324578221a7f7/torchvision-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torchvision) (10.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from requests->transformers) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from requests->transformers) (2024.12.14)\r\n",
      "Downloading torchvision-0.21.0-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: torchvision\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.17.2\r\n",
      "    Uninstalling torchvision-0.17.2:\r\n",
      "      Successfully uninstalled torchvision-0.17.2\r\n",
      "Successfully installed torchvision-0.21.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T14:08:26.340764Z",
     "start_time": "2025-04-03T14:08:26.335654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, QuantoConfig\n",
    "\n",
    "class ConversationMemory:\n",
    "    def __init__(self):\n",
    "        self.conversation = []\n",
    "\n",
    "    def add_message(self, speaker: str, text: str):\n",
    "        self.conversation.append((speaker, text))\n",
    "\n",
    "    def get_context(self) -> str:\n",
    "        return \"\\n\".join(f\"{s}: {t}\" for (s, t) in self.conversation)\n",
    "\n",
    "    def clear_memory(self):\n",
    "        self.conversation = []\n",
    "\n",
    "def generate_response(model, tokenizer, prompt, max_new_tokens=128, device='cpu'):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_p=0.95,\n",
    "            top_k=50,\n",
    "            temperature=0.7,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "def main():\n",
    "    model_name = \"deepseek-ai/DeepSeek-V3\"\n",
    "\n",
    "    # Decide which device to use (MPS if available, else CPU)\n",
    "    device = \"cpu\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 1) Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "    # 2) Load model on CPU first to avoid quantization errors\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=QuantoConfig(weights=\"int4\")\n",
    "    )\n",
    "\n",
    "    # 3) Move model to MPS or stay on CPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    memory = ConversationMemory()\n",
    "\n",
    "    print(\"Deepseek Chat. Type 'quit' to exit.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"User: \").strip()\n",
    "        if user_input.lower() == \"quit\":\n",
    "            print(\"Bot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        memory.add_message(\"User\", user_input)\n",
    "\n",
    "        conversation_context = memory.get_context()\n",
    "        prompt = (\n",
    "            \"The following is a conversation between a user and an AI assistant. \"\n",
    "            \"The AI assistant is helpful, polite, and knowledgeable.\\n\\n\"\n",
    "            f\"{conversation_context}\\nBot:\"\n",
    "        )\n",
    "\n",
    "        full_response = generate_response(model, tokenizer, prompt, device=device)\n",
    "        # Extract just the bot's new text\n",
    "        bot_response = full_response.split(\"Bot:\")[-1].strip()\n",
    "        memory.add_message(\"Bot\", bot_response)\n",
    "\n",
    "        print(f\"Bot: {bot_response}\")"
   ],
   "id": "5a221bc8007486e9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T14:08:29.335205Z",
     "start_time": "2025-04-03T14:08:28.337200Z"
    }
   },
   "cell_type": "code",
   "source": "main()",
   "id": "9e05e97a39a6157f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No GPU found. A GPU is needed for FP8 quantization.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[3], line 42\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     39\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name, trust_remote_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# 2) Load model on CPU first to avoid quantization errors\u001B[39;00m\n\u001B[0;32m---> 42\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquantization_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mQuantoConfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mint4\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m# 3) Move model to MPS or stay on CPU\u001B[39;00m\n\u001B[1;32m     49\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:568\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    566\u001B[0m     \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mregister(config\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, model_class, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    567\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m add_generation_mixin_to_remote_model(model_class)\n\u001B[0;32m--> 568\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    569\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    570\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    571\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    572\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n",
      "File \u001B[0;32m~/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:272\u001B[0m, in \u001B[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    270\u001B[0m old_dtype \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mget_default_dtype()\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 272\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    274\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_default_dtype(old_dtype)\n",
      "File \u001B[0;32m~/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:4292\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   4289\u001B[0m     hf_quantizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   4291\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m hf_quantizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 4292\u001B[0m     \u001B[43mhf_quantizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate_environment\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4293\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4294\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_tf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4295\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_flax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4296\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4297\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweights_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4298\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4299\u001B[0m     torch_dtype \u001B[38;5;241m=\u001B[39m hf_quantizer\u001B[38;5;241m.\u001B[39mupdate_torch_dtype(torch_dtype)\n\u001B[1;32m   4300\u001B[0m     device_map \u001B[38;5;241m=\u001B[39m hf_quantizer\u001B[38;5;241m.\u001B[39mupdate_device_map(device_map)\n",
      "File \u001B[0;32m~/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages/transformers/quantizers/quantizer_finegrained_fp8.py:51\u001B[0m, in \u001B[0;36mFineGrainedFP8HfQuantizer.validate_environment\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     46\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConverting into FP8 weights from tf/flax weights is currently not supported, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     47\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease make sure the weights are in PyTorch format.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     48\u001B[0m     )\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[0;32m---> 51\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo GPU found. A GPU is needed for FP8 quantization.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     53\u001B[0m compute_capability \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mget_device_capability()\n\u001B[1;32m     54\u001B[0m major, minor \u001B[38;5;241m=\u001B[39m compute_capability\n",
      "\u001B[0;31mRuntimeError\u001B[0m: No GPU found. A GPU is needed for FP8 quantization."
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
