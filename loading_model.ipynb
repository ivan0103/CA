{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T14:06:41.076219Z",
     "start_time": "2025-04-03T14:06:38.967270Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install transformers torch accelerate torchvision",
   "id": "1c9b9b0579b000a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (4.50.3)\r\n",
      "Requirement already satisfied: torch in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (2.6.0)\r\n",
      "Requirement already satisfied: optimum-quanto in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (0.2.7)\r\n",
      "Requirement already satisfied: accelerate in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (1.6.0)\r\n",
      "Requirement already satisfied: torchvision in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (0.17.2)\r\n",
      "Requirement already satisfied: filelock in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (3.17.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (0.30.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch) (3.1.5)\r\n",
      "Requirement already satisfied: fsspec in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: ninja in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from optimum-quanto) (1.11.1.4)\r\n",
      "Requirement already satisfied: psutil in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from accelerate) (6.1.1)\r\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting torchvision\r\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/29/88/00c69db213ee2443ada8886ec60789b227e06bb869d85ee324578221a7f7/torchvision-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torchvision) (10.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from requests->transformers) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from requests->transformers) (2024.12.14)\r\n",
      "Downloading torchvision-0.21.0-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: torchvision\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.17.2\r\n",
      "    Uninstalling torchvision-0.17.2:\r\n",
      "      Successfully uninstalled torchvision-0.17.2\r\n",
      "Successfully installed torchvision-0.21.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T15:33:48.256892Z",
     "start_time": "2025-04-03T15:33:48.249173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, QuantoConfig\n",
    "\n",
    "class ConversationMemory:\n",
    "    def __init__(self):\n",
    "        self.conversation = []\n",
    "\n",
    "    def add_message(self, speaker: str, text: str):\n",
    "        self.conversation.append((speaker, text))\n",
    "\n",
    "    def get_context(self) -> str:\n",
    "        return \"\\n\".join(f\"{s}: {t}\" for (s, t) in self.conversation)\n",
    "\n",
    "    def clear_memory(self):\n",
    "        self.conversation = []\n",
    "\n",
    "def generate_response(model, tokenizer, prompt, max_new_tokens=128, device='cpu'):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_p=0.95,\n",
    "            top_k=50,\n",
    "            temperature=0.7,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "def main():\n",
    "    model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "    # Decide which device to use (MPS if available, else CPU)\n",
    "    device = \"cpu\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 1) Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "    # 2) Load model on CPU first to avoid quantization errors\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        # quantization_config=QuantoConfig(weights=\"int4\")\n",
    "    )\n",
    "\n",
    "    # 3) Move model to MPS or stay on CPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    memory = ConversationMemory()\n",
    "\n",
    "    print(\"Deepseek Chat. Type 'quit' to exit.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"User: \").strip()\n",
    "        if user_input.lower() == \"quit\":\n",
    "            print(\"Bot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        memory.add_message(\"User\", user_input)\n",
    "\n",
    "        conversation_context = memory.get_context()\n",
    "        prompt = (\n",
    "            \"The following is a conversation between a user and an AI assistant. \"\n",
    "            \"The AI assistant is helpful, polite, and knowledgeable.\\n\\n\"\n",
    "            f\"{conversation_context}\\nBot:\"\n",
    "        )\n",
    "\n",
    "        full_response = generate_response(model, tokenizer, prompt, device=device)\n",
    "        # Extract just the bot's new text\n",
    "        bot_response = full_response.split(\"Bot:\")[-1].strip()\n",
    "        memory.add_message(\"Bot\", bot_response)\n",
    "\n",
    "        print(f\"Bot: {bot_response}\")"
   ],
   "id": "5a221bc8007486e9",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-03T15:33:59.453480Z"
    }
   },
   "cell_type": "code",
   "source": "main()",
   "id": "9e05e97a39a6157f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
